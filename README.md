## üìÅ Projet Data Warehouse : Analyse des Ventes de Supermarch√©

Ce projet a pour objectif la mise en place d'un **Entrep√¥t de Donn√©es (Data Warehouse)** pour un supermarch√©, en utilisant le processus **ETL (Extraction, Transformation, Chargement)** int√©gralement d√©velopp√© en Python.

L'entrep√¥t est mod√©lis√© selon un **Sch√©ma en √âtoile** pour permettre l'analyse multidimensionnelle (OLAP) des ventes par produit, client, p√©riode et localisation. 

### Objectifs Principaux
* Construire un mod√®le en √©toile comprenant une Table de Faits (`VENTES`) et quatre Dimensions (`DIM_PRODUIT`, `DIM_TEMPS`, `DIM_CLIENT`, `DIM_MAGASIN`).
* Impl√©menter le pipeline ETL en **Python** (avec Pandas/SQLAlchemy).
* R√©aliser des analyses OLAP pour identifier les tendances de vente et le comportement client.

***

## üõ†Ô∏è Pr√©requis Techniques

Pour ex√©cuter ce projet, vous devez disposer des outils et librairies suivants :

### 1. Environnement
* **Python 3.x**
* **SGBD :** PostgreSQL (ou MySQL/MariaDB).

### 2. Librairies Python

Installez toutes les d√©pendances requises en utilisant `pip` :

```bash
pip install -r requirements.txt
```

Le fichier `requirements.txt` doit contenir au minimum :
```bash
pip install -r requirements.txt
```pandas
sqlalchemy
# Choisissez le connecteur appropri√© √† votre BDD
psycopg2-binary  # Pour PostgreSQL
# mysql-connector-python  # Pour MySQL
```
## üöÄ Guide de D√©marrage Rapide
### √âtape 1 : Configuration de la Base de Donn√©es
1. Assurez-vous que votre instance PostgreSQL (ou autre SGBD) est en cours d'ex√©cution.

2. Cr√©ez la base de donn√©es cible (ex: supermarket_dw).

3. Ex√©cutez le script DDL pour cr√©er les tables de l'entrep√¥t :
```bash
# Exemple de commande psql
psql -U votre_utilisateur -d supermarket_dw -f 03_BDD_SQL/01_DDL_Creation_Schema.sql
```
### √âtape 2 : Configuration de la Connexion
Modifiez le fichier `03_BDD_SQL/connexion_db.py` (ou le fichier o√π vous d√©finissez votre SQLAlchemy Engine) avec vos identifiants de connexion.

Exemple de cha√Æne de connexion SQLAlchemy : `'postgresql://utilisateur:motdepasse@localhost:5432/supermarket_dw'`

### √âtape 3 : Ex√©cution du Pipeline ETL
Le script principal orchestre l'extraction, la transformation et le chargement dans le bon ordre (Dimensions puis Faits).

Ex√©cuter le script principal :
```bash
python 02_Scripts_Python_ETL/etl_main.py
```

### √âtape 4 : Analyse et V√©rification
1. Ex√©cuter les requ√™tes OLAP : Utilisez le fichier 03_BDD_SQL/02_DQL_OLAP_Queries.sql pour interroger la base de donn√©es et obtenir les analyses demand√©es.

2. Visualisation : Connectez votre outil de BI (Metabase, Power BI, etc.) √† la base de donn√©es supermarket_dw pour g√©n√©rer le tableau de bord de visualisation.

## üìÇ Structure des Dossiers
R√©f√©rence de la structure des fichiers du projet :

* 01_Sources_Brutes/: Fichiers de donn√©es initiaux (supermarket_sales.csv, produits, clients...).

* 02_Scripts_Python_ETL/: Scripts Python de transformation et de chargement.

* 03_BDD_SQL/: Scripts SQL de cr√©ation de tables et d'analyse.

* 04_Analyses_Visualisations/: Sorties de l'analyse et du tableau de bord.

* 05_Livrables/: Rapport final et pr√©sentation.

* README.md (ce fichier)

* requirements.txt